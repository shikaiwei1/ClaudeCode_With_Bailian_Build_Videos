# Agent-视频自动制作平台。
使用ClaudeCode、Cursor、Trae或其他AI Agent作为平台，通过百炼中提供的模型，完成从剧本到Videos的创作

## 功能说明

本项目通过Agent平台+MCP工具，完成自动化的视频制作。

1. 输入视频的剧本，由Agent通过交互修改的方式，生成视频的分镜头脚本。
2. 生成角色图：包括角色名称、角色描述（prompt）。并使用MCP工具，根据角色描述，生成角色的图片。
3. 生成分镜头视频：根据分镜头脚本和角色，调用MCP工具，生成分镜头视频。
4. 调用ffmpeg，将分镜头视频和角色图片，合并成一个视频文件。

## 环境说明
- ffmpeg：用于视频合并。
- MCP工具：用于生成角色图片和视频。
- Agent平台：ClaudeCode、Cursor、Trae等。
  
### 1. ffmpeg安装
请至[ffmpeg官网](https://ffmpeg.org/download.html)下载build包，并确保放入PATH中。

### 2. MCP工具安装（可选）

> 请至[阿里云百炼](https://www.aliyun.com/product/bailian)注册账号，并获取API Key。

目前用到2个MCP工具，基于阿里云百炼，请将获取的API Key，替换到下面的配置中，并添加到你的AI工具中
1. 文生图

```
{
  "mcpServers": {
    "bailian-image": {
      "command": "uvx",
      "args": [
        "mcp-server-bailian-image"
      ],
      "env": {
        "DASHSCOPE_API_KEY": "替换你的阿里云百炼Key"
      }
    }
  }
}
```

2. 图生视频

```
{
  "mcpServers": {
    "bailian-video-synthesis": {
      "command": "uvx",
      "args": [
        "mcp-server-bailian-video-synthesis"
      ],
      "env": {
        "DASHSCOPE_API_KEY": "替换你的阿里云百炼Key"
      }
    }
  }
}
```


---请将一下内容，复制到Agent的项目说明文档中，如CLAUDE.md中---
这是一个视频自动制作平台，使用ClaudeCode、Cursor、Trae或其他AI Agent作为平台，通过百炼中提供的模型，完成从剧本到Videos的创作。

# 目录说明
 - ./src 辅助代码文件
 - ./template 模板文件
 - ./work* 工作目录，每个视频一个目录，在具体执行时，过程数据会记录在这个文件夹中。
   - ./work/*/script.md 视频的分镜头脚本,包括镜头序号、画面描述、字幕内容、使用时长、 参与角色、视频URL等。另外用户的原始输入的剧本，也可以放在里面用于记录。
   - ./work/*/roles.md 视频的角色信息（角色描述、文生图Prompt、完成生成的图片URL）
   - ./work/*/images/roles 用于存放下载后的角色图片，用角色名称命名
   - ./work/*/images/background 用于存放背景图片。
   - ./work/*/videos 视频的分镜头视频，每个镜头一个视频文件，用镜头序号命名
   - ./work/*/audio 视频的分镜头解说音频，每个镜头一个音频文件，用镜头序号命名
   - ./work/*/final.mp4 视频的最终输出文件
   - ./work/*/log.txt 视频制作过程的日志文件
   - ./work/*/src 执行过程中所需的临时脚本文件（由ai临时编写）

# 环境说明
- ffmpeg：用户视频合成步骤，地址位于：<这里替换你本地ffmpeg的执行位置，如：/usr/local/bin/ffmpeg>
- MCP工具：用于生成角色图片和视频。（可选）其中：
  - 文生图：使用bailian-image模型，通过API调用生成纯色背景的角色正面图片。
  - 图生视频：使用bailian-video-synthesis模型，通过API调用生成视频。
- 阿里云百炼平台调用示例（可选）其中：
  - src/example/bailian_multimodal_generation.py ： 其中有语音合成示例，用于生成字幕。
  - src/example/bailian_text2image_image_synthesis_v2.py ： 其中有文生图示例，用于生成角色图片、背景图片。
  - src/example/bailian_uploads.py ： 其中有上传文件示例。用于在有必要时，将文件上传到阿里云百炼平台，并将URL做为模型输入。
  - src/example/bailian_video_generation_video_synthesis.py ： 其中有图生视频示例，用于生成视频。其中最重要的是“多图参考（image_reference）”功能，用于将角色图片、背景图片生成分镜头视频。
- python：用于执行过程脚本。

# 工作步骤
## 0. 理解用户本次希望制作的视频内容

如果用户未给出剧本，你需要通过交互，询问用户本次希望制作的视频内容，如：视频的主题、视频的时长、视频的角色、视频的场景等。

## 1. 新建工作目录：

- 环境检查：运行src/environment_check.py 检查环境是否满足要求。如果不满足，与用户交互补全环境。
- work目录下，新建一个用视频主题命名的目录，如：work/<视频主题>

## 2. 完成角色信息文件roles.md和分镜头脚本文件script.md

a. 根据将用户的基础意图写入文件，抽提角色清单，并创建roles.md文件。
   - 每个角色，包括角色名称、角色描述（prompt）。
   - 角色描述，要详细到可以用文生图生成角色图片的程度。
   - 角色描述生成的图片是一张静态全身图，切为白色背景。必要时可以添加负向提示词用于约束，避免生成人物的背景图。
b. 根据用户输入，创建script.md文件：
   - 使用表格记录每个镜头的画面描述，要详细到可以用文生视频的程度，其中包括了场景、角色、动作、环境等。
   - 镜头间的转场和留白等无需ai生成的部分，需要单独一行进行记录。
   - 由于模型能力限制，每个视频长度不可超过5秒。（模型生成的视频长度固定为5s时，合并时可以使用其中部分剪辑片段）
   - 每个镜头的使用时长，要根据视频的总时长，和角色的动作快慢，合理分配。
c. 邀请用户审阅并修改上述文件内容，直到用户确认可以进行下一步。

## 3. 生成角色图片及背景图片
a. 从roles.md文件中，提取角色名称和角色描述。
b. 根据示例编写代码或调用MCP工具，根据角色描述，生成角色的图片。
c. 将生成的图片，保存到./work/<视频主题>/images/roles目录下，用角色名称命名。
d. 将图片的URL，写入roles.md文件中。
e. 重复步骤a-d，直到所有角色的图片都生成完毕。
f. 从script.md文件中，提取背景描述。
g. 根据示例编写代码或调用MCP工具，根据背景描述，生成背景图片。
h. 将生成的图片，保存到./work/<视频主题>/images/background目录下，用背景图片所涉及到的场景命名。
i. 邀请用户审阅所有角色图片，并响应用户修改需求重新生成图片，直到用户确认所有图片都符合要求。

## 4. 生成分镜头视频
a. 从script.md文件中，提取镜头序号、画面描述、字幕内容、使用时长、参与角色。
b. 根据示例编写代码或调用MCP工具，根据画面描述和字幕内容，生成视频。注意：角色图最多3张。此时，你应当调用image_reference。
c. 由于是异步接口，请在请求生成视频后，等待视频生成完成，将生成的视频，保存到./work/<视频主题>/videos目录下，用镜头序号命名。
d. 重复步骤a-c，直到所有镜头的视频都生成完毕。
e. 注意：由于视频生成较慢，当有4个及以上任务处于等待或正在生成的状态时，你可以sleep 180秒，等待视频生成完成。

## 5. 根据字幕生成解说
a. 从script.md文件中，提取字幕内容。
b. 根据示例编写代码或调用MCP工具，根据字幕内容，生成分镜头解说音频。
c. 将生成的音频，保存到./work/<视频主题>/audio目录下，用镜头序号命名。

## 5. 合并视频
a. 根据script.md文件中的表格对镜头进行合并、增加字幕，并增加转场、留白效果。注意：AI生成视频时长与script.md中记录的使用时长可能有差异。需要在拼接时根据脚本中标记时长，对生成的ai视频进行截取再行拼接。
b. 调用ffmpeg，根据合并后的脚本，生成最终的视频文件。
c. 字幕请注意，必须要和视频同步，不能提前或延迟。
d. 将合并后的视频，保存到./work/<视频主题>/final.mp4文件中。
